{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "compte-rendu-traitement-images.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "-7LwCXyE942V"
      },
      "outputs": [],
      "source": [
        "Sylvan LE DEUNFF\n",
        "\n",
        "# Projet Traitement et Analyse d’Images\n",
        "# IMR3 – 2019-2020\n",
        "# Classification d’images\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Aujourd'hui la croissance du numérique, et le développement des services Cloud amènent une explosion du nombre de documents multimédias à stocker. En particulier les images qui sont omniprésentes sur les réseaux sociaux comme Facebook, Instagram ou Snapchat. Pour pouvoir rechercher ces images ou en extraire de l'information, on peut utiliser des métadonnées, mais celles-ci sont bien souvent incomplètes ou erronnées. Il devient donc nécessaire de pouvoir classifier ces images non-plus selon leur métadonnées, mais en se basant sur leur contenu.\n",
        "\n",
        "Pour ce TP, nous nous intéressons à une problématique de classification d'images. L'objectif ici est donc d'être en mesure d'attribuer une étiquette (classe) à une image à partir de son contenu. Pour cela nous comparerons 2 approches :\n",
        "\n",
        "- la classification basée sur des vecteurs de distances entre les primitives de l'image.\n",
        "- la classification par un réseau de neurones convolutif.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "TwHpzLEeFDQE"
      },
      "outputs": [],
      "source": [
        "## Préparation des données\n",
        "\n",
        "Ici les images étudiées proviennent de la base de données Corel. C'est un ensemble d'image provenant d'une galerie photo de même nom, qui ont été labellisés et rangées dans des répertoires portant les noms de ces étiquettes.\n",
        "\n",
        "*Exemple de structure de la BDD*\n",
        "```\n",
        "coreldb\n",
        "├── ...\n",
        "├── pet_cat\n",
        "└── pet_dog\n",
        "```\n",
        "\n",
        "### Répartition des données en 3 sous-ensembles\n",
        "\n",
        "Avant de nous attaquer à un problème de classification d'images, il convient pour chaque feature de répartir les données en 3 sous-ensembles. A savoir :\n",
        "\n",
        "* **apprentissage**: ce sont les données qui seront utilisées pour entraîner notre modèle.\n",
        "\n",
        "* **validation**: les données de cet ensemble ne sont pas utilisées lors de l'apprentissage. elles permettront d'ajuster les hyper-paramètres du modèle.\n",
        "\n",
        "* **test**: ces données servent à évaluer la précision d'un modèle *après entrainement*. Il est essentiel qu'elles n'aient pas servi pendant les phases d'apprentissage ou de test. Dans le cas contraire, on risque de sur-entrainer notre modèle qui ne fera plus à proprement parler des \"prédictions\" mais de la mémorisation.\n",
        "\n",
        "|Ensemble|Proportion|\n",
        "|-|-|\n",
        "|Apprentissage|70%|\n",
        "|Validation|15%|\n",
        "|Test|15%|\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "from random import shuffle\n",
        "\n",
        "COREL_DB_PATH = 'coreldb'\n",
        "WORKSPACE_DB = 'database'\n",
        "\n",
        "def random_classes(n):\n",
        "  \"\"\"\n",
        "  Tire au maximum n classes aléatoires parmi celles contenues dans la base COREL.\n",
        "  \"\"\"\n",
        "  # liste les fichiers disponibles dans le répertoire de la base COREL\n",
        "  files = os.listdir(COREL_DB_PATH)\n",
        "\n",
        "  classes = list(filter(lambda file: (\n",
        "      # conserve uniquement les classes (répertoires)\n",
        "      os.path.isdir(os.path.join(COREL_DB_PATH, file))\n",
        "      # ignore les repertoire caches (systeme) sous linux\n",
        "      and not file.startswith('.')\n",
        "  ), files))\n",
        "\n",
        "  # melange (en place) la liste de classes\n",
        "  shuffle(classes)\n",
        "\n",
        "  # retourne les n (au plus) premieres classes\n",
        "  return classes[:n]\n",
        "  \n",
        "\n",
        "def split_classes_data(classes):\n",
        "  \"\"\"\n",
        "  Reparti pour chaque classe les images en 3 sous-repertoires.\n",
        "  Proportion: train=70% validation=15% test=15%\n",
        "  \"\"\"\n",
        "  try:\n",
        "    # supprime la base de tests precendente si elle existe\n",
        "    shutil.rmtree(WORKSPACE_DB)\n",
        "  except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "  # recrée un répertoire pour la base de tests\n",
        "  os.mkdir(WORKSPACE_DB)\n",
        "\n",
        "  # crée 3 répertoires pour répartir nos classes\n",
        "  folders = ('train', 'validation', 'test')\n",
        "  for folder in folders:\n",
        "    os.mkdir(os.path.join(WORKSPACE_DB, folder))\n",
        "  \n",
        "  # pour chacune des classes choisies\n",
        "  for classe in classes:\n",
        "    # recupere les images disponibles dans la base COREL\n",
        "    images = os.listdir(os.path.join(COREL_DB_PATH, classe))\n",
        "    shuffle(images)\n",
        "    # calcule en fonction du nombre d'image les indices des slices\n",
        "    n = len(images)\n",
        "    indexes = [0, int(0.7*n), int(0.85*n), n]\n",
        "    \n",
        "    for k in range(3):\n",
        "      # cree le repertoire de la classe dans chaque sous-repertoire\n",
        "      os.mkdir(os.path.join(WORKSPACE_DB, folders[k], classe))\n",
        "      # déplace les images de la base COREL vers la base de travail\n",
        "      for image in images[indexes[k]: indexes[k+1]]:\n",
        "        shutil.copy(\n",
        "            os.path.join(COREL_DB_PATH, classe, image),\n",
        "            os.path.join(WORKSPACE_DB, folders[k], classe, image)\n",
        "        )\n",
        "\n",
        "classes = random_classes(2)\n",
        "split_classes_data(classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "0D5pr2VgQsWu"
      },
      "outputs": [],
      "source": [
        "Après exécution de ce script la base de travail générée est la suivante.\n",
        "\n",
        "```\n",
        "database/\n",
        "├── test\n",
        "│   ├── pet_cat\n",
        "│   └── pet_dog\n",
        "├── train\n",
        "│   ├── pet_cat\n",
        "│   └── pet_dog\n",
        "└── validation\n",
        "    ├── pet_cat\n",
        "    └── pet_dog\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {
        "colab_type": "text",
        "id": "7L2GWTUnHsf0"
      },
      "outputs": [],
      "source": [
        "## Classification d'images basée sur leurs attributs (CBIR)\n",
        "\n",
        "Nous allons à présent chercher à classifier des images en fonctions de leurs attributs. Pour cela nous nous appuyons sur la librairie suivante :\n",
        "\n",
        "https://github.com/pochih/CBIR/"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Classification par un CNN\n",
        "\n",
        "Un réseau de neurones convolutif (CNN) est un algorithme d'apprentissage profond qui peut prendre une image d'entrée, attribuer une importance à divers aspects/objets de l'image et être capable de les différencier les uns des autres. Le prétraitement requis dans un CNN est beaucoup moins important que dans d'autres algorithmes de classification. En effet les méthodes basées sur l'analyse des primitives comme le CBIR, nécessitent de concevoir les filtres à la main, ce qui demande des connaissances d'expertise. A l'inverse, les CNN ont la capacité d'apprendre \"naturellement\" ces filtres/caractéristiques.\n",
        "\n",
        "L'architecture d'un CNN est analogue à celle du schéma de connectivité des neurones dans le cerveau humain et s'inspire de l'organisation du cortex visuel. Les neurones individuels répondent aux stimuli que dans une région restreinte du champ visuel appelée le champ de réception. Un ensemble de ces champs se chevauchent pour couvrir la totalité de la zone visuelle.\n",
        "\n",
        "![](https://miro.medium.com/max/1255/1*vkQ0hXDaQv57sALXAJquxA.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Préparation des données\n",
        "\n",
        "![](https://miro.medium.com/max/550/1*15yDvGKV47a0nkf5qLKOOQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Structure du NN utilisé"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Entrainement du modèle\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Tests du modèle et évaluation des résultats\n",
        "\n",
        "Afin d'évaluer les qualité des prédictions effectuées, on définit une fonction :\n",
        "```\n",
        "test_model(model, mode, output_images=False)\n",
        "```\n",
        "où\n",
        "- **model**: est un classifieur ayant été entrainé.\n",
        "- **mode**: type de classification (valeurs possibles: `binary` ou `categorical`)\n",
        "- **output_images**: défini s'il faut écrire les résultats dans le répertoire `<database>/output`\n",
        "\n",
        "Cette fonction\n",
        "- charge les images du répertoire `<database>/test` sous forme d'un générateur\n",
        "- test le modèle entrainé, avec les images de test"
      ]
    },
    {
      "cell_type": "markdown",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### Paramètres de l'apprentissage\n",
        "\n",
        "- **batch_size** détermine le nombre d'échantillons dans chaque mini lot. Son maximum est le nombre de tous les échantillons, ce qui rend la descente de gradient précise, la perte diminuera vers le minimum si le taux d'apprentissage est assez faible, mais les itérations sont plus lentes. Son minimum est de 1, ce qui entraîne une descente stochastique du gradient : Rapide mais la direction du pas du gradient n'est basée que sur un seul exemple, la perte peut sauter. batch_size permet d'ajuster entre les deux extrêmes : direction précise du gradient et itération rapide. De plus, la valeur maximale de batch_size peut être limitée si votre modèle + ensemble de données ne rentre pas dans la mémoire disponible (GPU).\n",
        "\n",
        "- **steps_per_epoch** le nombre d'itérations par lot avant qu'une époque d'entraînement ne soit considérée comme terminée. Si vous avez un ensemble d'entraînement de taille fixe, vous pouvez l'ignorer mais cela peut être utile si vous avez un ensemble de données énorme ou si vous générez des augmentations de données aléatoires à la volée, c'est-à-dire si votre ensemble d'entraînement a une taille (générée) infinie. Si vous avez le temps de parcourir l'ensemble de votre ensemble de données d'entraînement, je vous recommande de ne pas tenir compte de ce paramètre.\n",
        "\n",
        "- **validation_steps** similaire à steps_per_epoch mais sur l'ensemble des données de validation au lieu des données d'entraînement. Si vous avez le temps de passer en revue l'ensemble de vos données de validation, je vous recommande de ne pas utiliser ce paramètre.\n"
      ]
    }
  ]
}